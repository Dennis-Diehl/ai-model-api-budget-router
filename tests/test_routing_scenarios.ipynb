{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing-Szenarien: Token-, Kosten- und Modellauswahl-Tests\n",
    "\n",
    "Dieses Notebook verifiziert die realistischere Token- und Kostenschätzung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from backend.cost_estimator import estimate_tokens, estimate_output_tokens, estimate_cost\n",
    "from backend.budget_guard import check_budget\n",
    "from backend.routing import select_model\n",
    "from backend.model_config import MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Token-Schätzung: verschiedene Textarten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {\n",
    "    \"English (short)\": \"Hello, how are you doing today?\",\n",
    "    \"English (medium)\": \"The quick brown fox jumps over the lazy dog. \" * 20,\n",
    "    \"German (Fachsprache)\": \"Datenschutzgrundverordnung und Informationssicherheitsmanagement sind entscheidend.\",\n",
    "    \"Python Code\": \"\"\"def fibonacci(n):\\n    if n <= 1:\\n        return n\\n    a, b = 0, 1\\n    for _ in range(2, n + 1):\\n        a, b = b, a + b\\n    return b\\n\"\"\",\n",
    "    \"JSON Code\": '{\"users\": [{\"id\": 1, \"name\": \"Alice\"}, {\"id\": 2, \"name\": \"Bob\"}]}',\n",
    "    \"Empty\": \"   \",\n",
    "}\n",
    "\n",
    "print(f\"{'Text':<25} {'Chars':>6} {'Tokens':>7} {'Chars/Token':>12}\")\n",
    "print(\"-\" * 55)\n",
    "for label, text in texts.items():\n",
    "    tokens = estimate_tokens(text)\n",
    "    ratio = len(text) / tokens if tokens > 0 else 0\n",
    "    print(f\"{label:<25} {len(text):>6} {tokens:>7} {ratio:>12.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Output-Schätzung: Task-Types × Prompt-Längen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_types = [\"general\", \"code\", \"email\", \"summarize\"]\n",
    "input_token_counts = [50, 200, 500, 2000]\n",
    "model_max = 32768\n",
    "\n",
    "print(f\"{'Task Type':<12} {'Input':>7} {'Output':>8} {'Ratio':>7}\")\n",
    "print(\"-\" * 40)\n",
    "for task in task_types:\n",
    "    for inp in input_token_counts:\n",
    "        out = estimate_output_tokens(inp, task, model_max)\n",
    "        print(f\"{task:<12} {inp:>7} {out:>8} {out/inp:>7.1f}x\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Routing-Szenarien: welches Modell wird gewählt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_prompt = \"Schreib mir eine kurze E-Mail an meinen Chef.\"\n",
    "long_prompt = \"Erkläre mir ausführlich die Funktionsweise von Transformern in neuronalen Netzen. \" * 30\n",
    "code_prompt = \"\"\"def merge_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    mid = len(arr) // 2\\n    left = merge_sort(arr[:mid])\\n    right = merge_sort(arr[mid:])\\n    return merge(left, right)\\n\"\"\" * 5\n",
    "\n",
    "scenarios = [\n",
    "    (\"Short + email + 0.01 + medium\",   short_prompt, \"email\",     0.01,  \"medium\"),\n",
    "    (\"Short + email + 0.001 + medium\",  short_prompt, \"email\",     0.001, \"medium\"),\n",
    "    (\"Long + summarize + 0.01 + high\",  long_prompt,  \"summarize\", 0.01,  \"high\"),\n",
    "    (\"Long + general + 0.01 + medium\",  long_prompt,  \"general\",   0.01,  \"medium\"),\n",
    "    (\"Code + code + 0.05 + high\",       code_prompt,  \"code\",      0.05,  \"high\"),\n",
    "    (\"Code + code + 0.001 + low\",       code_prompt,  \"code\",      0.001, \"low\"),\n",
    "    (\"Short + general + 0.001 + low\",   short_prompt, \"general\",   0.001, \"low\"),\n",
    "    (\"Long + code + 0.005 + medium\",    long_prompt,  \"code\",      0.005, \"medium\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Scenario':<40} {'Model':<30} {'Reason'}\")\n",
    "print(\"=\" * 110)\n",
    "for label, prompt, task, budget, quality in scenarios:\n",
    "    try:\n",
    "        model_id, reason = select_model(prompt, task, budget, quality)\n",
    "        model_name = MODELS[model_id][\"name\"]\n",
    "        print(f\"{label:<40} {model_name:<30} {reason}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"{label:<40} {'--- KEIN MODELL ---':<30} {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kosten-Vergleichstabelle: alle Modelle für denselben Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"Erkläre mir die Grundlagen von Machine Learning und gib Beispiele für Anwendungen.\"\n",
    "\n",
    "for task in task_types:\n",
    "    print(f\"\\n--- Task: {task} ---\")\n",
    "    print(f\"{'Model':<30} {'Input Tok':>10} {'Output Tok':>11} {'Cost ($)':>12}\")\n",
    "    print(\"-\" * 68)\n",
    "    input_tokens = estimate_tokens(test_prompt)\n",
    "    for model_id, config in MODELS.items():\n",
    "        out_tokens = estimate_output_tokens(input_tokens, task, config[\"max_tokens\"])\n",
    "        cost = estimate_cost(model_id, input_tokens, out_tokens)\n",
    "        print(f\"{config['name']:<30} {input_tokens:>10} {out_tokens:>11} {cost:>12.8f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
